# Phase 2: Adding Hadoop HDFS to the infrastructure

services:
  # MySQL with OpenMRS database (from Phase 1)
  mysql:
    container_name: mysql
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: openmrs
      MYSQL_DATABASE: openmrs
      MYSQL_USER: openmrs
      MYSQL_PASSWORD: openmrs
    ports:
      - "3306:3306"
    volumes:
      - ./data/mysql/data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-popenmrs"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Zookeeper (required for Kafka)
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka broker
  kafka-broker:
    container_name: kafka-broker
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server=localhost:9092 --list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s

  # Hadoop NameNode
  hadoop-namenode:
    container_name: hadoop-namenode
    build:
      context: ../docker/hadoop/namenode
    image: hadoop-namenode:latest
    ports:
      - "9870:9870"  # Web UI
      - "9000:9000"  # HDFS
    volumes:
      - ./data/hdfs/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop-cluster
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - default

  # Hadoop DataNode 1
  hadoop-datanode1:
    container_name: hadoop-datanode1
    build:
      context: ../docker/hadoop/datanode
    image: hadoop-datanode:latest
    depends_on:
      hadoop-namenode:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    volumes:
      - ./data/hdfs/datanode1:/hadoop/dfs/data
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - default

  # Hadoop DataNode 2
  hadoop-datanode2:
    container_name: hadoop-datanode2
    build:
      context: ../docker/hadoop/datanode
    image: hadoop-datanode:latest
    depends_on:
      hadoop-namenode:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    volumes:
      - ./data/hdfs/datanode2:/hadoop/dfs/data
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - default

  # Kafka Connect with Debezium and HDFS Sink
  kafka-connect:
    container_name: kafka-connect
    image: debezium/connect:2.1
    depends_on:
      kafka-broker:
        condition: service_healthy
      mysql:
        condition: service_healthy
      hadoop-namenode:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      BOOTSTRAP_SERVERS: kafka-broker:9092
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      # Add these to ensure topics are created properly
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      # Add these for better logging
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      # Add these for better connector configuration
      CONNECT_PLUGIN_PATH: /kafka/connect
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
    restart: on-failure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    volumes:
      - ./pipelines:/kafka-connect-configs
